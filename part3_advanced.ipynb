{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Advanced Analysis\n",
    "\n",
    "In this part, we will implement advanced analysis techniques for physiological time series data, including time-domain feature extraction, frequency analysis, and wavelet transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "import pywt\n",
    "import os\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time-Domain Feature Extraction\n",
    "\n",
    "Implement the `extract_time_domain_features` function to extract various time-domain features from physiological signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_time_domain_features(data, window_size=60):\n",
    "    \"\"\"Extract time-domain features from physiological signals.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        Input data with columns: ['timestamp', 'heart_rate', 'eda', 'temperature', 'subject_id', 'session']\n",
    "    window_size : int, optional\n",
    "        Size of the rolling window in seconds, default=60\n",
    "        \n",
    "    Returns\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing extracted features for each window\n",
    "    \"\"\"\n",
    "    # Convert window_size from seconds to number of samples\n",
    "    # Assuming data is sampled at 1 Hz (1 sample per second)\n",
    "    window_samples = window_size\n",
    "    \n",
    "    # Initialize DataFrame for features\n",
    "    features = pd.DataFrame()\n",
    "\n",
    "    # Basic statistics using rolling window\n",
    "    features['mean'] = data['heart_rate'].rolling(window=window_samples).mean()\n",
    "    features['std'] = data['heart_rate'].rolling(window=window_samples).std()\n",
    "    features['min'] = data['heart_rate'].rolling(window=window_samples).min()\n",
    "    features['max'] = data['heart_rate'].rolling(window=window_samples).max()\n",
    "\n",
    "    # Heart rate statistics\n",
    "    features['mean_hr'] = data['heart_rate'].rolling(window=window_samples).mean()\n",
    "    features['std_hr'] = data['heart_rate'].rolling(window=window_samples).std()\n",
    "\n",
    "    # Beat-to-beat variability (RR intervals)\n",
    "    rr_intervals = 60000 / data['heart_rate']  # Convert HR to RR intervals in ms\n",
    "\n",
    "    # Calculate successive differences within each window\n",
    "    rr_diff = rr_intervals.diff()\n",
    "\n",
    "    # RMSSD (Root Mean Square of Successive Differences)\n",
    "    features['rmssd'] = np.sqrt(rr_diff.rolling(window=window_samples).apply(lambda x: np.mean(x**2)))\n",
    "\n",
    "    # SDNN (Standard Deviation of NN intervals)\n",
    "    features['sdnn'] = rr_intervals.rolling(window=window_samples).std()\n",
    "\n",
    "    # pNN50 (Percentage of successive RR intervals differing by >50ms)\n",
    "    features['pnn50'] = rr_diff.rolling(window=window_samples).apply(\n",
    "        lambda x: 100 * np.sum(np.abs(x) > 50) / len(x) if len(x) > 0 else 0\n",
    "    )\n",
    "\n",
    "    # Drop NaN values from rolling window calculations\n",
    "    features = features.dropna()\n",
    "    \n",
    "    # Adding units to feature names\n",
    "    features = features.rename(columns={\n",
    "        'mean': 'mean_hr_bpm',\n",
    "        'std': 'std_hr_bpm',\n",
    "        'min': 'min_hr_bpm',\n",
    "        'max': 'max_hr_bpm',\n",
    "        'mean_hr': 'mean_hr_bpm',\n",
    "        'std_hr': 'std_hr_bpm',\n",
    "        'rmssd': 'rmssd_ms',\n",
    "        'sdnn': 'sdnn_ms',\n",
    "        'pnn50': 'pnn50_percent'\n",
    "    })\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_hr_bpm  std_hr_bpm  min_hr_bpm  max_hr_bpm  mean_hr_bpm  std_hr_bpm  \\\n",
      "69   103.575320    3.166833      92.144   109.03125   103.575320    3.166833   \n",
      "70   103.436761    3.105347      92.144   107.93950   103.436761    3.105347   \n",
      "71   103.471394    3.061761      92.144   107.93950   103.471394    3.061761   \n",
      "72   103.453879    3.075626      92.144   107.93950   103.453879    3.075626   \n",
      "73   103.530704    2.940071      92.144   107.93950   103.530704    2.940071   \n",
      "\n",
      "     rmssd_ms    sdnn_ms  pnn50_percent  \n",
      "69  12.410593  18.517500       1.666667  \n",
      "70  11.686480  18.215249       1.666667  \n",
      "71   8.948408  17.959284       0.000000  \n",
      "72   8.643004  18.035993       0.000000  \n",
      "73   7.395482  17.191729       0.000000  \n"
     ]
    }
   ],
   "source": [
    "def load_processed_data(processed_dir='data/processed'):\n",
    "    \"\"\"Load and concatenate all processed data CSVs.\"\"\"\n",
    "    all_files = [f for f in os.listdir(processed_dir) if f.endswith('.csv')]\n",
    "    dfs = []\n",
    "    for file in all_files:\n",
    "        df = pd.read_csv(os.path.join(processed_dir, file))\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df = load_processed_data()\n",
    "\n",
    "heart_rate_data = df[['timestamp', 'heart_rate']].dropna()  # Remove NaN values\n",
    "\n",
    "# Extract time-domain features with a window size of 60 seconds\n",
    "time_domain_features = extract_time_domain_features(heart_rate_data, window_size=60)\n",
    "\n",
    "# Show the resulting features DataFrame\n",
    "print(time_domain_features.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Frequency Analysis\n",
    "\n",
    "Implement the `analyze_frequency_components` function to perform frequency-domain analysis on the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_frequency_components(data, sampling_rate, window_size=60, output_dir='results'):\n",
    "    \"\"\"Perform frequency-domain analysis on physiological signals.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        Input data with columns: ['timestamp', 'heart_rate', 'eda', 'temperature', 'subject_id', 'session']\n",
    "    sampling_rate : float\n",
    "        Sampling rate of the signal in Hz\n",
    "    window_size : int, optional\n",
    "        Size of the analysis window in seconds, default=60\n",
    "    output_dir : str\n",
    "        Directory to save analysis results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing frequency analysis results\n",
    "    \"\"\"\n",
    "    # Convert window_size from seconds to number of samples\n",
    "    window_samples = int(window_size * sampling_rate)\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "    \n",
    "    # Process data in windows\n",
    "    n_windows = len(data) // window_samples\n",
    "    all_frequencies = []\n",
    "    all_power = []\n",
    "    \n",
    "    # Loop over windows and compute the PSD for each window\n",
    "    for i in range(n_windows):\n",
    "        window_data = data['heart_rate'].iloc[i*window_samples:(i+1)*window_samples]\n",
    "        \n",
    "        # Check if the window is valid (not empty)\n",
    "        if len(window_data) < window_samples:\n",
    "            print(f\"Warning: Window {i} is too small, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate PSD using Welch's method\n",
    "        frequencies, power = signal.welch(\n",
    "            window_data,\n",
    "            fs=sampling_rate,\n",
    "            nperseg=window_samples\n",
    "        )\n",
    "        \n",
    "        # Handle NaN values in the power spectrum\n",
    "        power = np.nan_to_num(power)\n",
    "        \n",
    "        all_frequencies.append(frequencies)\n",
    "        all_power.append(power)\n",
    "    \n",
    "    # Average results across windows\n",
    "    results['frequencies'] = np.mean(all_frequencies, axis=0)\n",
    "    results['power'] = np.mean(all_power, axis=0)\n",
    "    \n",
    "    # Define frequency bands\n",
    "    bands = {\n",
    "        'VLF': (0.003, 0.04),\n",
    "        'LF': (0.04, 0.15),\n",
    "        'HF': (0.15, 0.4)\n",
    "    }\n",
    "    \n",
    "    # Calculate power in each band\n",
    "    results['bands'] = {}\n",
    "    for band_name, (low, high) in bands.items():\n",
    "        mask = (results['frequencies'] >= low) & (results['frequencies'] <= high)\n",
    "        results['bands'][band_name] = np.sum(results['power'][mask])\n",
    "    \n",
    "    # Calculate LF/HF ratio\n",
    "    results['bands']['LF/HF'] = results['bands']['LF'] / results['bands']['HF']\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the frequency analysis results to a file\n",
    "    file_path = os.path.join(output_dir, 'frequency_analysis_results.npz')\n",
    "    np.savez(file_path, frequencies=results['frequencies'], power=results['power'], bands=results['bands'])\n",
    "    \n",
    "    # Return the results dictionary\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies: [0.         0.01666667 0.03333333 0.05       0.06666667 0.08333333\n",
      " 0.1        0.11666667 0.13333333 0.15       0.16666667 0.18333333\n",
      " 0.2        0.21666667 0.23333333 0.25       0.26666667 0.28333333\n",
      " 0.3        0.31666667 0.33333333 0.35       0.36666667 0.38333333\n",
      " 0.4        0.41666667 0.43333333 0.45       0.46666667 0.48333333\n",
      " 0.5       ]\n",
      "Power Spectrum: [2.42500611e+01 2.02959384e+02 3.50286751e+01 6.16905849e+00\n",
      " 2.40114986e+00 9.15700935e-01 3.94089041e-01 3.20582525e-01\n",
      " 2.33316806e-01 1.54621839e-01 1.10042100e-01 8.45787088e-02\n",
      " 7.86833241e-02 7.58325358e-02 6.00559930e-02 2.71567503e-02\n",
      " 3.03198200e-02 3.65697700e-02 3.14062517e-02 4.10020397e-02\n",
      " 5.20363629e-02 4.90619325e-02 4.62397153e-02 6.98359031e-02\n",
      " 7.00608492e-02 8.31668024e-02 6.38772233e-02 3.95099362e-02\n",
      " 6.54156915e-02 5.70124876e-02 5.77926412e-02]\n",
      "Power in Bands: {'VLF': 237.9880595252225, 'LF': 10.433897654273556, 'HF': 1.0175038953888316, 'LF/HF': 10.2544056111808}\n"
     ]
    }
   ],
   "source": [
    "sampling_rate = 1\n",
    "results = analyze_frequency_components(df, sampling_rate=sampling_rate, window_size=60)\n",
    "print(\"Frequencies:\", results['frequencies'])\n",
    "print(\"Power Spectrum:\", results['power'])\n",
    "print(\"Power in Bands:\", results['bands'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time-Frequency Analysis\n",
    "\n",
    "Implement the `analyze_time_frequency_features` function to analyze time-frequency features using wavelet transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_time_frequency_features(data, sampling_rate, window_size=60, output_dir='results'):\n",
    "    \"\"\"Analyze time-frequency features using wavelet transforms.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        Input data with columns: ['timestamp', 'heart_rate', 'eda', 'temperature', 'subject_id', 'session']\n",
    "    sampling_rate : float\n",
    "        Sampling rate of the signal in Hz\n",
    "    window_size : int, optional\n",
    "        Size of the analysis window in seconds, default=60\n",
    "    output_dir : str, optional\n",
    "        Directory to save analysis results, default='results'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing time-frequency analysis results\n",
    "    \"\"\"\n",
    "    # Convert window_size from seconds to number of samples\n",
    "    window_samples = int(window_size * sampling_rate)\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "    \n",
    "    # Define wavelet scales (frequency bands)\n",
    "    scales = np.arange(1, 128)\n",
    "    results['scales'] = scales\n",
    "    \n",
    "    # Process data in windows\n",
    "    n_windows = len(data) // window_samples\n",
    "    all_coefficients = []\n",
    "    all_energy = []\n",
    "    \n",
    "    for i in range(n_windows):\n",
    "        window_data = data['heart_rate'].iloc[i*window_samples:(i+1)*window_samples]\n",
    "        \n",
    "        # Check if window contains sufficient data for wavelet transform\n",
    "        if len(window_data) < window_samples:\n",
    "            print(f\"Warning: Window {i} is too small, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Apply continuous wavelet transform (CWT) using Morlet wavelet\n",
    "        coefficients, frequencies = pywt.cwt(\n",
    "            window_data,\n",
    "            scales,\n",
    "            'morl',\n",
    "            sampling_period=1/sampling_rate\n",
    "        )\n",
    "        \n",
    "        all_coefficients.append(coefficients)\n",
    "        all_energy.append(np.abs(coefficients)**2)  # Energy is the square of the coefficient magnitude\n",
    "    \n",
    "    # Average results across windows\n",
    "    results['coefficients'] = np.mean(all_coefficients, axis=0)\n",
    "    results['time_frequency_energy'] = np.mean(all_energy, axis=0)\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save the results as an .npz file\n",
    "    file_path = os.path.join(output_dir, 'wavelet_analysis_results.npz')\n",
    "    np.savez(file_path, scales=results['scales'], coefficients=results['coefficients'], energy=results['time_frequency_energy'])\n",
    "    \n",
    "    # Return the results dictionary\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_time_frequency_features(df, sampling_rate, window_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Here's how to use these functions with your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "data = pd.read_csv('data/processed/S1_processed.csv')\n",
    "\n",
    "# Extract time-domain features\n",
    "features = extract_time_domain_features(data, window_size=60)\n",
    "print(\"Time-domain features:\")\n",
    "print(features.head())\n",
    "\n",
    "# Analyze frequency components\n",
    "sampling_rate = 4.0  # Hz\n",
    "freq_results = analyze_frequency_components(data, sampling_rate, window_size=60)\n",
    "print(\"\\nFrequency analysis results:\")\n",
    "print(\"Frequency bands:\", freq_results['bands'])\n",
    "\n",
    "# Analyze time-frequency features\n",
    "tf_results = analyze_time_frequency_features(data, sampling_rate, window_size=60)\n",
    "print(\"\\nTime-frequency analysis results:\")\n",
    "print(\"Wavelet scales:\", tf_results['scales'].shape)\n",
    "print(\"Coefficients shape:\", tf_results['coefficients'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
